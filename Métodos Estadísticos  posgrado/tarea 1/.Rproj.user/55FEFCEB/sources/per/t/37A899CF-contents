---
title: "Taller 1"
author: "Valentina Gonzalez Ruiz - Andres Felipe Beltran Rodriguez"
date: "10/23/2021"
output:
  word_document: default
  pdf_document: default
extra_dependencies:
- supertabular
- booktabs
fig_caption: yes
classoption: twocolumn
highlight: tango
---
<!-- \usepackage{supertabular,booktabs} -->

## 1. Con la variable gastos semanales de los empleados en una empresa construya:

a. una distribución de frecuencias, de frecuencias relativas, acumuladas, y relativas acumuladas.

Para resolver este punto debemos ingresar los datos a R:

```{r cargando los datos 1, message = F}
library(readxl)
tarea1 <- read_excel("./tarea1.xlsx")
```

Luego podemos separar solo la variable gastos en un vector:

```{r separamos los datos gastos}
gastos <- tarea1$gastos
```

Para definir la cantidad de intervalos en los cuales separar los datos, podemos utilizar la ecuacion de sturges [(Sturges 1926)](https://www.tandfonline.com/doi/abs/10.1080/01621459.1926.10502161)


$$
\begin{array}{c}
k = 1 + 3.332 \cdot log(n)
\end{array}
$$

* n = tamaño de muestra, número de observaciones
* k = número de intervalos

podemos revisar el tamaño de muestra con la función `length()` de R:

```{r revisando el tamaño de muestra}
length(gastos)
```

Para esta muestra de 90 individuos:

$$
\begin{array}{c}
k = 1 + 3.332 \cdot log(90)
\end{array}
$$
Podemos entonces introducir la ecuación a R. y calcular la cantidad de intervalos a utilizar:


```{r calculando la cantidad de intervalos}
k <- 1 + (3.322 * log10(90))
k
```
Dado que no podemos seleccionar 7.491994 intervalos, podemos rendondear al número entero más cercano con `0`
cifras decimales:


```{r redondeando la cantidad de intervalos}
round(k,0)
```

$$
\begin{array}{c}
7 \approx 7.491994 = 1 + 3.332 \cdot log(90)
\end{array}
$$

Para este conjunto de datos podemos utilizar 7 intervalos. Para saber el tamaño del intervalo, podemos dividir el rango en el número de intervalos:

$$
\begin{array}{c}
longitud \; del \; intervalo = \frac{max(gastos)-min(gastos)}{7}
\end{array}
$$

```{r}
LongInt <- (max(gastos)-min(gastos))/7
LongInt
```

La longitud del intervalo es $15565.86 \approx 15566$.

```{r}
LongInt <- round(LongInt,0) 
LongInt
```
Podemos entonces construir la tabla de valores minimos y máximos para este intervalo:

Primero calculamos los límites inferiores de los 7 intervalos, Teniendo encuenta que ya tenemos el primero, `min(gastos)`, tenemos que calcular los 6 restantes. 

```{r}

mins <- seq(min(gastos), 
            min(gastos)+((LongInt))*6,
            by = LongInt)

```


Para calcular los límites superiores, basta con sumar la longitud del intervalo - 1, ya que uno de los valores del intervalo ya está (el límite inferior que calculamos en el paso anterior): 

```{r}
maxs <- mins + LongInt-1

TDF <- data.frame(
  min = mins,
  max = maxs
)
TDF
```

Ahora podemos iterar a lo largo de las filas de la tabla de frecuencias `TDF` buscando cuantos elementos de `gastos` están dentro de cada intervalo definido por cada fila.
 
```{r}
for(i in 1: nrow(TDF)){
  
  TDF$fi[i] <- length(
    which(
TDF$min[i] <= gastos & gastos <= TDF$max[i]
    )
  )
  
}
TDF
```

Una vez tenemos la frecuencia absoluta, podemos calcular la frecuencia relativa dividiendo por el numero de observaciones:

```{r}
TDF$fr <- round(TDF$fi/length(gastos),2)
TDF
```

Una vez tenemos las frecuencias absolutas y relativas, podemos calcular las acumuladas de la siguiente manera:

* Primero para la frecuencia absoluta acumulada$(F_i)$:

```{r}
for(i in 1:nrow(TDF)){
  
  TDF$Fi[i] <- sum(TDF$fi[1:i]) 
  
}

```

  En donde `sum(TDF$fi[1:i])` suma todas todas las frecuencias absolutas presentes en la columna `fi` desde la posición 1, hasta la posición de la nueva columna `Fi` que se está llenando. Si el contador está en la tercera posición, `i = 3` entonces la tercera posición de la columna `Fi`, `TDF$Fi[3]`, será la suma de todos los elementos desde el primero, `TDF$fi[1]` hasta el tercero, `TDF$fi[3]`, por esto el uso del operador dos puntos `:`.
  

* También para la frecuencia relativa acumulada$(F_r)$:

```{r, echo =F}
options(knitr.table.format = "latex")
```


```{r}
for(i in 1:nrow(TDF)){
  
  TDF$Fr[i] <- sum(TDF$fr[1:i]) 
  
}

```


Una vez hemos calculado todas las frecuencias, podemos imprimir la tabla final:

```{r, echo  = F}
TDF2 <- TDF
colnames(TDF2) <- c('min.',
                   'max.',
                   'f~i~',
                   'f~r~',
                   'F~i~',
                   'F~r~'
                   
                   )
```
\onecolumn
```{r}
knitr::kable(TDF2,"simple") 
```

\twocolumn

Para observar los resultados de la tabla de frecuencias, podemos hacer un histograma del porcentaje de frecuencia relativa en funcion de los intervalos:


```{r}
library(ggplot2)

intervalos <- sort(factor(paste(TDF$min,'-',TDF$max),
                     levels = paste(TDF$min,'-',TDF$max),) )
ggplot(TDF,
aes(x = reorder(intervalos,intervalos, function(x)-length(x)),
y = fr*100,
fill=intervalos,
label = round(fr*100,2)
)
) +
geom_bar(stat="identity") +
xlab("intervalo") +
ylab('% frecuencia relativa')+
geom_label(aes(fill = intervalos),
colour = "white",
fontface = "italic") +
 theme(axis.text.x = element_blank())
```

c. Interpretar los resultados mostrados por el gráfico. Qué puede decir de la distribución
de los datos?

* La distribución muestra que las mayores frecuencias estan en el intervalo de 55566 a 71131, y que hay un sesgo hacia la cola derecha. 

### Medidas descriptivas de localización y dispersión
d. Calcule las medidas descriptivas de localización y variabilidad incluyendo el primer cuartil y el decil siete. Interpretar los resultados obtenidos.

La media se calcula con la funcion `mean()`

```{r }
mean(gastos)
```

* En una semana, los gastos promedio de los empleados de la empresa entrevistados para la muestra utilizada son 91307.11

La mediana se calcula con la funcion `median()`

```{r }
median(gastos)
```

Para su interpretación, también podemos hallar el mínimo y el máximo usando la función `quantile()`

```{r}
quantile(gastos)
```
Dentro de los empleados de la empresa, que fueron entrevistados en la muestra analizada, la mitad, o el 50\% tiene gastos semanales entre 40000 y 88021, mientras que la otra mitad, o el otro 50\% tienen gastos semanales entre 88021 y 148961. 


Para calcular la moda creamos una funcion `moda()`

```{r }

moda <- function(x) {                    
  v <- unique(x)
  t <- tabulate(match(x, v))
  v[t == max(t)]
}
moda(gastos)
```

* Los gastos mas frecuentes en los empleados entrevistados en la muestra analizada son 50000, 60000, 65000 y 75000


La desviacion estandar y la varianza muestral se calcula con las funciones `sd()` y `var()`
```{r }
sd(gastos)
var(gastos)
```

* La desviacion de los gastos semanales de los empleados utilizados en la muestra, respecto al valor promedio es de 29527.13 pesos

Para calcular el rango se le resta al maximo dato el minimo:

```{r }
Rango<-max(gastos)-min(gastos)
Rango
```

*El mayor gasto semanal de los empleados entrevistados en la muestra 108961 más costoso que el gasto semanal minimo de la muestra analizada.


Para calcular el coeficiente de variación creamos la funcion `Coefvar()`:

```{r }
CoefVar<-function(x){
  sd(x)/mean(x)*100
}
CoefVar(gastos)

```

* Dado que el coeficiente de variación de gastos semanales en la muestra de empleados analizada es mayor al 20% los gastos semanales en la muestra son heterogeneos.

Ahora, para cada turno de trabajo, podemos separar la muestra en turnos.

Primero revisamos cuantos turnos hay:

```{r}
turnos <- unique(tarea1$turno)
turnos
```
Luego, podemos separar la información de gastos semanales por turno:

```{r, message = F}
library(dplyr) 
gastosDiurno <- filter(tarea1, turno == 'diurno') %>% select(gastos) %>% unlist 
```

Una vez tenemos todos los datos de gastos semanales correspondientes al turno diurno de la muestra analizada, podemos calcular el coeficiente de variación utilizando la función `CoefVar()` pasando como argumento el vector `gastosDiurno`:

```{r}
CoefVar(gastosDiurno)
```
Podemos realizar una operación análoga para los otros dos turnos.

```{r}
gastosTarde <- filter(tarea1, turno == 'tarde') %>% select(gastos) %>% unlist
gastosNocturna <- filter(tarea1, turno == 'nocturna') %>% select(gastos) %>% unlist
CoefVarTurno <- round(data.frame(diurno = CoefVar(gastosDiurno),
                           tarde =CoefVar(gastosTarde), nocturna =CoefVar(gastosNocturna)),2)
```

y visualizamos los resultados:
\center
```{r}
knitr::kable(CoefVarTurno, 'simple')
```
\center

Gracias a la tabla anterior, podemos afirmar que en los tres turnos de trabajo, se observa heterogeneidad en los gastos semanales de los empleados entrevistados para la muestra analizada.



**Cuartiles y deciles**

Para calcular cuartiles se usa la función `quantile()` 
```{r }
quantile(gastos)
```

* Primer cuartil :el 25% de los gastos de la empresa tienen un valor e 40000 hasta 66050 y el 75% restante tienen un valor de 66050 hasta 148961

Para calcular el rango intercuartilico se usa la función `IQR()` 
```{r }
IQR(gastos)

```

* El 50% de los gastos de la empresa tienen un valor de 66050 hasta 115041.2 

Para calcular deciles se usa la función `quantile()` 
```{r }
quantile(gastos,probs = seq(0,1,0.1))
```
>
* Septimo decil: El 70% de los gastos de la empresa tienen un valor de 40000 hasta 110067.8 y el 30% restante tienen un valor de 110067.8 hasta 148961


e. Qué puede decir respecto a la simetría y curtosis en la distribución de los datos, justificar la respuesta e interprete estas medidas.

### Símetria y curtosis

```{r }
library(e1071)
skewness(gastos)
kurtosis(gastos)
```

* Como el resultado del coeficiente de asimetria es mayor a 0, la distribucion es asimetria a la derecha, es decir que hay un sesgo hacia la derecha. 

* La curtosis dio un resultado negativo indicando una distribucion platocurtica, mas aplastada que la distribucion normal y con una mayor dispersión que la de una distribución normal estándar.

f. Qué proporción de mediciones está dentro de 1.5 desviaciones estándar de la media, a dos desviaciones estándar de la media y a tres desviaciones estándar de la media, concluya?

Para calcular que proporcion de los datos estan en 1,5 2 y 3 desviaciones estandar de la media, obtenemos estos rangos de datos:  
```{r }
Rango1.5sd<-c(mean(gastos)-(1.5*sd(gastos)),mean(gastos)+(1.5*sd(gastos)))
length(which(gastos>Rango1.5sd[1]  & gastos <Rango1.5sd[2]))/length(gastos)*100

Rango2sd<-c(mean(gastos)-(2*sd(gastos)),mean(gastos)+(2*sd(gastos)))
length(which(gastos>Rango2sd[1]  & gastos <Rango2sd[2]))/length(gastos)*100

Rango3sd<-c(mean(gastos)-(3*sd(gastos)),mean(gastos)+(3*sd(gastos)))
length(which(gastos>Rango3sd[1]  & gastos <Rango3sd[2]))/length(gastos)*100


```
>
*El 87,7% de las mediciones esta dentro de 1.5 desviaciones estándar de la media y el 100% de las mediciones esta dentro de 2 y 3 desviaciones estándar de la media.

g. Cuál de las medidas de localización y de variabilidad recomendaría y porque?

>
* Para estos datos la mejor medida de tendencia central serian las modas, ya que como se ve en el histograma la mayoria de gastos se encuentran en el intervalo entre 55566 y 71131 que coincide con las modas, la media y la mediana se ven afectadas por el sesgo a la derecha y sus valores son mayores a 8000. La mejor medida de varianza podria ser el rango intercuartilico ya que no se ve tan afectado por la media como la desviacion estandar.

h. Calcule los coeficientes de variación por turno para la variable gastos semanales y diga en cuál de los turnos hay más homogeneidad, interprete.
Coeficientes de variacion por turno
```{r }
empresa<-tarea1[c(2,4)]
empresa$turno<-as.factor(empresa$turno)
diurno<-subset(empresa,turno == "diurno")
tarde<-subset(empresa,turno == "tarde")
nocturna<-subset(empresa,turno == "nocturna")

CoefVar(diurno$gastos)
CoefVar(tarde$gastos)
CoefVar(nocturna$gastos)

```
>
* El menor coeficiente de variacion lo tiene el turno de la tarde (25.5%) por lo que es el turno con mayor homogeneidad, le sigue el turno nocturno (34.7%) que es mas heterogeneo y finalmente el turno diurno (37.2) que es el mas heterogeneo de los 3. 


## 2. De las variables jornada y turno construya:
a. Una tabla de frecuencias para el cruce de las dos variables y concluya.
```{r }
library(gmodels)
CrossTable(tarea1$turno,tarea1$jornada,prop.chisq=F)
```
>
* El 31% de las personas esta en el turno diurno, de este grupo un 35.7% esta en jornada completa, otro 35.7 % esta en la jornada media y el 28.6% restante esta en jornada parcial.
El 35.6% de las personas esta en el turno nocturno, de este grupo un 40.6% esta en jornada completa, otro 40.6 % esta en la jornada media y el 18.8% restante esta en jornada parcial.
El 33.3% de las personas esta en el turno tarde, de este grupo un 26.7% esta en jornada completa, un 20 % esta en la jornada media y el 53.3% restante esta en jornada parcial.
En el turno diurno y nocturno hay menor cantidad de personas en jornada parcial, en cambio en el turno tarde la mayoria de personas esta en la jornada parcial.
Al parecer no se asocian mucho las variables 

b. Un histograma de frecuencias relativas (darlas en porcentajes).
c. Interpretar los resultados mostrados por el gráfico. Qué puede decir de la distribución de los datos?
```{r,warning = FALSE }
tarea1$turno<-as.factor(tarea1$turno)
tarea1$jornada<-as.factor(tarea1$jornada)
tablaf<-table(tarea1$turno,tarea1$jornada)
tFrecRel<-as.data.frame(tablaf/90*100) 
colnames(tFrecRel)<-c("Turno","Jornada","Frecuencia Relativa")
ggplot(tFrecRel, aes(fill=tFrecRel$Turno, y=tFrecRel$`Frecuencia Relativa` , x= tFrecRel$Jornada)) + 
    geom_bar(position="dodge", stat="identity")+
xlab("Jornada") +
ylab('% Frecuencia relativa')+ scale_fill_discrete(name = "Turno")

```
>
* En la jornada completa y media siguen la misma tendencia, en donde la mayoria de personas estan en el turno nocturno y la minoria en el turno tarde, mientras que en la jornada parcial la mayoria de personas esta en el turno tarde y la minoria en el turno noche. Los graficos muestran que las variables no estan asociadas.


d. Diga si hay asociación entre las dos variables con un nivel de significancia de 0.05 e interprete el resultado.
Para determinar si hay asociacion se hace un test Ji- cuadrado de Pearson con la funcion `chisq.test()` 
```{r}
chisq.test(tarea1$turno,tarea1$jornada)
```
>
* En este caso como el valor de alfa es 0.05 y el p-valor es 0.063 es mayor la hipotesis nula se rechaza es decir que no hay asociacion entre la jornada y los turnos.

e. Construya la tabla de frecuencias correspondiente al hábito de fumar y jornada laboral, concluya.

```{r }
tarea1$fuma <-as.factor(tarea1$fuma)
CrossTable(tarea1$fuma,tarea1$jornada,prop.chisq=F)
```
>
* El 28% de las personas no fuma, de este grupo un 32% esta en jornada completa, otro 42.9 % esta en la jornada media y el 25% restante esta en jornada parcial.
El 68.9% de las personas fuma, de este grupo un 35.5% esta en jornada completa, otro 27.4 % esta en la jornada media y el 37.1% restante esta en jornada parcial.
La mayoria de las personas que no fuman estan en la jornada media, mientras que las que fuman estan en su mayoria en la jornada parcial o completa.
Las variables no estan muy asociadas entre si.


f. Hay asociación entre el hábito de fumar de los empleados y la jornada laboral con un nivel de significancia de 0.05. Interprete el resultado?

```{r,warning = FALSE}
chisq.test(tarea1$fuma,tarea1$jornada)

```
>
* En este caso como el valor de alfa es 0.05 y el p-valor es 0.311 es mayor la hipotesis nula se rechaza es decir que no hay asociacion entre la jornada y el habito de fumar de los empleados.

## 3. Con el archivo adjunto de fresa

a. Realizar el boxplot de la variable gradosbrixa para frutos de fresa por tratamientob (0.25 g/m2 de Nitrogeno (N), 0.20 g/m2 de anhídrido fosfórico (P2O5), 0.15 g/m2 de
óxido de potasa (K2O) e interprete el gráfico correspondiente.

```{r cargando los datos 2, message = F}
library(readxl)
fresa <- read_excel("./tarea1.xlsx", sheet =2)
```

```{r identificando NA}
nas <- which(is.na(fresa$gradosbrixa))

colores<-c("#00AFBB", "#E7B800", "#FC4E07")

df1 <- data.frame(gradosbrixa = fresa$gradosbrixa[-nas],
                  tratamientob = as.factor(fresa$tratamientob[-nas]))
library(ggplot2)
ggplot(df1,
       aes( x = tratamientob,
            y = gradosbrixa,
            fill = tratamientob)) +
  
  geom_boxplot()

```

* Podemos ver que para el tratamiento B 1 los grados bix A presentan un outlier, además la mediana no esta en el centro de la caja indicando un ligero sesgo hacia la cola derecha; tiene el rango mas grande de los tres tratamientos. 

para el tratamiento B 2 el rango es mas pequeño pero estos datos tienen mas dispersion, como se puede ver por el ancho de la caja, tambien presenta un ligero sesgo hacia la izquierda. Finalmente, el tratamiento B 3 es el que tiene menor rango y se ve simetrico. Estas afirmaciones se pueden soportar calculando los momentos de curtosis y de sesgo.


b. Realizar el boxplot para la variable consistenciac en frutos de fresa por tratamientoc (0.10 g/m2 óxido de magnesio (MgO), 20 g/m2 de Nitrógeno, 10 g/m2 de anhídrido
fosfórico (P2O5)), e interprete el gráfico correspondiente.

```{r }
boxplot(fresa$consistenciac ~ fresa$tratamientoc, xlab = "Tratamiento C", ylab = "Consistencia C", col= colores)
```

* En los 3 tratamientos vemos que se encuentran outliers, estos datos de consistencia C son tan grandes que no permiten ver muy bien la distribución de los demas datos 

c. Realizar el boxplot para la variable gradosbrixb en frutos de fresa por tratamientob (0.25 g/m2 de Nitrogeno (N), 0.20 g/m2 de anhídrido fosfórico (P2O5), 0.15 g/m2 de
óxido de potasa (K2O) de anhídrido fosfórico (P2O5)), e interprete el gráfico correspondiente.

```{r}
nasb <- which(is.na(fresa$gradosbrixb))

df2 <- data.frame(gradosbrixb = fresa$gradosbrixb[-nasb],
                  tratamientob = as.factor(fresa$tratamientob[-nasb]))
library(ggplot2)
ggplot(df2,
       aes( x = tratamientob,
            y = gradosbrixb,
            fill = tratamientob)) +
  
  geom_boxplot()

```

c. Construya una tabla de frecuencias completa para la variable consistenciaa en frutos de fresa y realice el gráfico de barras que le permita ver la distribución de frecuencias
relativas en porcentaje e interprete.

Primero separamos la variable consistenciaa en un vector:

```{r}
nas3 <- which(is.na(fresa$consistenciaa))
consistenciaa <- fresa$consistenciaa[-nas3]

length(consistenciaa)
```
Para determinar la cantidad de intervalos de nuevo utilizamos la ecuación de sturges:

```{r}
k2 <- 1 + (3.322 * log10(84))
k2

```
```{r}
round(k2,0)
```
Tendremos para esta variable 7 intervalos. Para saber la longitud del intervalo:

```{r}
LongInt2 <- (max(consistenciaa)-min(consistenciaa))/7
round(LongInt2,4)

```
```{r}
mins2 <- seq(min(consistenciaa), 
            min(consistenciaa)+((LongInt2))*6,
            by = LongInt2)

```

```{r}
maxs2 <- mins2 + LongInt2-0.0001
maxs2[7] <- maxs2[7] + 0.0001
TDFc <- data.frame(
  min = round(mins2,4),
  max = round(maxs2,4))

TDFc
```


realizamos los conteos:

```{r}
for(i in 1: nrow(TDFc)){
  
  TDFc$fi[i] <- length(
    which(
TDFc$min[i] <= consistenciaa & consistenciaa <= TDFc$max[i]
    )
  )
  
}
TDFc
```

```{r}
TDFc$fr <- TDFc$fi/length(consistenciaa)
```



```{r}
for(i in 1:nrow(TDFc)){
  
  TDFc$Fi[i] <- sum(TDFc$fi[1:i]) 
  
}

```


```{r}
for(i in 1:nrow(TDFc)){
  
  TDFc$Fr[i] <- sum(TDFc$fr[1:i]) 
  
}

```

```{r}
TDFc2 <- TDFc
colnames(TDFc2) <- c('min.',
                   'max.',
                   'f~i~',
                   'f~r~',
                   'F~i~',
                   'F~r~'
                   
                   )
```

```{r}

knitr::kable(TDFc2, 'simple')
```

```{r}
library(ggplot2)

intervalosc <- sort(factor(paste(TDFc$min,'-',TDFc$max),
                     levels = paste(TDFc$min,'-',TDFc$max),) )
ggplot(TDFc,
aes(x = reorder(intervalosc,intervalosc, function(x)-length(x)),
y = fr*100,
fill=intervalosc,
label = round(fr*100,2)
)
) +
geom_bar(stat="identity") +
xlab("intervalo") +
ylab('% frecuencia relativa')+
geom_label(aes(fill = intervalosc),
colour = "white",
fontface = "italic") +
 theme(axis.text.x = element_blank())

```

d. Construya la matriz de correlaciones de Pearson para las variables gradosbrixa
consistenciaa, gradosbrixb consistenciab, gradosbrixc y consistenciac y concluya.

primero revisamos cual variable tienen mas valores faltantes, asi escogeremos las muestras restantes para calcular la correlacion entre variables
```{r}
  
 which(is.na(fresa$gradosbrixa))
 which(is.na(fresa$consistenciaa))
 which(is.na(fresa$gradosbrixb))
 which(is.na(fresa$consistenciab))
  which(is.na(fresa$gradosbrixc))
 which(is.na(fresa$consistenciac))  
 
nasCor <-  which(is.na(fresa$gradosbrixa))

```
Una vez sabemos que escoger, podemos proceder a crear la tabla:

```{r}
df3 <-  data.frame(gradosbrixa = fresa$gradosbrixa[-nasCor],
consistenciaa = fresa$consistenciaa[-nasCor],
 gradosbrixb = fresa$gradosbrixb[-nasCor],
consistenciab = fresa$consistenciab[-nasCor],
 gradosbrixc = fresa$gradosbrixc[-nasCor],
consistenciac = fresa$consistenciac[-nasCor])

cor(df3)
```

```{r}
pairs(df3)
```

## 4. Con el archivo daños por sitio, correspondiente a una muestra de 480 cardones en la alta Guajira. Construya una tabla de frecuencias para el cruce de las variables tipo de daño (0= no hay daño, 1= corte con machete, 2= daño por insectos, 3= comido de cabras, 4= daño por viento, 5= daño por aves) y sitio (1= intervenido, 0= no intervenido).
a. Realizar el análisis respectivo, construya las tablas de frecuencias correspondientes

```{r}
cardones <- read_excel("./tarea1.xlsx", 
    sheet = "cardones")
cardones$`Tipo de Daño`<-as.factor(cardones$`Tipo de Daño`)
cardones$sitio<-as.factor(cardones$sitio)
attach(cardones)
CrossTable(`Tipo de Daño`,sitio,prop.chisq=F)
```
>
* Lo que se pueder ver en la tabla de contingencia es que al comparar el tipo de daño en los sitios internevidos y sin intervenir todos tienen valores muy similares excepto el daño 5, que es daño por aves, el 7% de los cardones sufre daño por aves y de este grupo el 82% esta en sitios no intervenidos y solo un 15.8% esta en sitios intervenidos.
Las variables estan asociadas entre si.

b. Hacer el histograma de las frecuencias relativas en porcentaje y concluya.
```{r,warning = FALSE}
tablef<-table(`Tipo de Daño`,sitio)
tableFrecRel<-as.data.frame(tablef/480*100) 
ggplot(tableFrecRel, aes(fill=tableFrecRel$Tipo.de.Daño, y=tableFrecRel$Freq , x= tableFrecRel$sitio)) +     geom_bar(position="dodge", stat="identity")+
xlab("Sitio") +ylab('% Frecuencia relativa')+ scale_fill_discrete(name = "Tipo de daño")+  geom_text(aes(label = round(tableFrecRel$Freq,2) ), vjust = 1.2, colour = "white", position = position_dodge(.9))


```
>
* Como lo muestra el histograma al comparar los sitios intervenido y los no internevidos las tendencias son similares, excepto para el daño 5 o daño por aves que tiene una frecuencia relativa mucho mayor en los sitios no intervenidos que en los intervenidos. Las variables sitios y tipo de daños estan relacionadas.


c. Hay asociación entre el tipo de daño y el sitio. Utilice un nivel de significancia del 0.05 y concluya?
```{r,warning = FALSE}
chisq.test(`Tipo de Daño`,sitio)

```
>
* En este caso como el valor de alfa es 0.05 y el p-valor es 0.00053 es menor, la hipotesis nula no se rechaza es decir que si hay asociacion entre la intervencion del sitio y el tipo de daño.





# Referencias

* Sturges, H. A. (1926). The choice of a class interval.  Journal of the american statistical association,  21(153), 65-66.
