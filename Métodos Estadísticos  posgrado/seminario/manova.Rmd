---
title: "MANOVA - ejemplo en R"
author: "Valentina gonzalez - Andres Beltran"
date: "2/8/2022"
output:
  rmdformats::downcute
---

# confirmación ejemplo excel

primero cargamos los datos:

```{r, message=FALSE, warning=FALSE}
library(heplots)
```
Luego podemos ver la estructura de los datos:

```{r}
str(RootStock)
```
creamos una matriz de datos adecuada para el test, y lo ejecutamos:

```{r}
root.manova <- manova(
                      cbind(
                        RootStock$girth4,
RootStock$ext4,
RootStock$girth15,
RootStock$weight15) ~ RootStock$rootstock, data = RootStock
                      
)
```




## Test de wilk

Luego guardamos el resumen con el estadístico de interés, el lambda de Wilk: 

```{r}
root.summary <- summary(root.manova,
                        test = 'Wilks')
```

Una vez tenemos guardado el resumen de resultados podemos imprimirlo:

```{r}
root.summary
```
También podemos imprimir las matrices H y E:

```{r}
root.summary$SS
```






# Ejemplo con iris, 2 variables

## Preparacion

Primero cargamos los paquetes que vamos a utilizar:

```{r, message = F, warning= F}
library(tidyverse)
library(ggpubr)
library(rstatix)
library(car)
library(broom)
```

## Preparacion de los datos

vamos a seleccionar dos columnas de interes, la longitud del sepalo y el petalo:

```{r}
iris2 <- iris %>%
  select(Sepal.Length, Petal.Length, Species) %>%
  add_column(id = 1:nrow(iris), .before = 1)
head(iris2)
```

## Visualizacion

Podemos graficar mediante un boxplot para cada especie, y para cada una de las dos variables usando `ggboxplot()`

```{r}
ggboxplot(
  iris2, x = "Species", y = c("Sepal.Length", "Petal.Length"), 
  merge = TRUE, palette = "jco"
  )
```

## Estadistica descriptiva

Podemos calcular el promedio y la desviacion estandar, por grupos (especies) para cada variable

```{r}
iris2 %>%
  group_by(Species) %>%
  get_summary_stats(Sepal.Length, Petal.Length, type = "mean_sd")
```

## Supuestos y pruebas preliminares

El análisis MANOVA presenta los siguientes supuestos:

* *tamaño de muestra adecuado* lo recomendable es que el número de observaciones por cada celda (un grupo dentro de una variable) debe ser mayor al numero de variables independientes
* *independencia de las observaciones:*
    + cada individuo debería pertenecer solo a un grupo.

    + No existe relación entre las observaciones entre los grupos.

     + No es posible tener réplicas para los individuos
     
     + la selección de la muestra debe ser aleatoria
     
* Ausencia de datos atípicos multivariados y univariados.

* Normalidad mutivariada, Se puede utilizar la función `mshapiro_test()` del paquete `rstatix` para realizar la prueba de shapuro'wilk para normalidad multivariada

* *Ausencia de multicolinearidad* las variables dependientes no deben estar correlacionadas. se aconseja correlacion menor a 0.9 
* *linealidad* entre la variable independiente y dependiente para cada grupo
* *Homogeneidad de varianzas* Para confirmar la igualdad de varianzas entre grupos puede utilizarse la prueba de levene, resultados no significantes indican que las varianzas entre grupos son iguales.

* *Homogeneidad de las matrices de varianza y covarianza* para revisar la igualdad de covarianza entre los grupos puede utilizarse la prueba de Box M. Esta prueba es un equivalente a la homogeneidad de varianza. 

Muy sensible, la significancia para esta rpueba se fija en alfa = 0.001

## prueba de tamaño de muestra

```{r}
iris2 %>%
  group_by(Species) %>%
  summarise(N = n())
```

En la tabla observamos 50 observaciones por grupo, un número mayor al número de variables.

## Identificación de datos atípicos univariados

Para identificar los datos atípicos en cada variable podemos usar la función `identify_outliers()`

Primero agrupamos los datos por especie:

```{r}
iris2 %>%
  group_by(Species) %>%
  identify_outliers(Sepal.Length)
```

El output de la función presenta que no hay datos atipicos extremos.

## detección de datos atípicos multivariados

Un dato atipico mutivariado es aquel que tiene una combinación inusual de valores en las variables independientes.

un método útil para detectar datos atípicos multivariados, es la distancia de mahalanobis, la cual nos dice que tan alejado está el punto del centro de la nube de puntos, teniendo en cuenta la forma o covarianza de la nuve.

```{r}
iris2 %>%
 group_by(Species) %>%
 mahalanobis_distance(-id) %>%
 filter(is.outlier == TRUE) %>%
  as.data.frame()
```

No se imprime ningun dato atipico multivariado

## Normalidad univariada

Podemos utilizar la prueba de shapiro wilk para cada variable dentro de cada grupo. Si los datos se distribuyen normalmente:

```{r}
iris2 %>%
  group_by(Species) %>%
  shapiro_test(Sepal.Length, Petal.Length) %>%
  arrange(variable)
```

Siempre y cuando el valor de p sea mayor a 0.05, la no es posible rechazar hipótesis nula de que la variable se distribuye normalmente

También es posible realizar una evaluación gráfica de la normalidad mediante el diagrama cuantil-cuantil


* Primero para el largo del sepalo por grupo
```{r}
# QQ plot de largo de sepalo
ggqqplot(iris2, "Sepal.Length", facet.by = "Species",
         ylab = "Sepal Length", ggtheme = theme_bw())
```

* Luego para el largo del petalo por grupo

```{r}
# QQ plot de largo de petalo
ggqqplot(iris2, "Petal.Length", facet.by = "Species",
         ylab = "Petal Length", ggtheme = theme_bw())
```
## normalidad multivariada

podemos usar la función `mshapiro_test()` para hacer la prueba de hipótesis de shapiro - wilk multivariada.

```{r}
iris2 %>%
  select(Sepal.Length, Petal.Length) %>%
  mshapiro_test()
```

Dado que el resutado del la prueba es un p-valor no significativo, podemos suponer que se presenta normalidad mutivariada.


## Identificación de multi colinealidad


Es ideal que la correlación entre las variables sea moderada, no mayor a 0.9. A su vez, si la correlación es muy baja entre las variables, es aconsejable utilizar ANOVA para cada variable por separado.

dado que tenemos dos variables podemos usar la función `cor_test()`. Si tenemos mas de dos variables, podemos usar la función `cor_mat()`:

```{r}
iris2 %>% cor_test(Sepal.Length, Petal.Length)
```

No existe multicolinealidad entre las variables, evaluado por la correlación de pearson. 0.87<0.9 usando un nivel de significancia de 0.0001.

## verificacion del supuesto de linealidad.

La realción entre las variables independientes debería ser lineal, si se compara por pares, para cada grupo. Podemos evaluar esta propiedad visualmente creando una matriz de dispersión usando la función `ggpairs()`, En el ejemplo de Iris, tenemos solo un par:

```{r, message=FALSE, warning=FALSE}
library(GGally)
resultado <- iris2 %>%
  select(Sepal.Length, Petal.Length, Species) %>%
  group_by(Species) %>%
  doo(~ggpairs(.) + theme_bw(), result = "plots")
resultado
resultado$plots
```

Gracias a los gráficos de dispersión podemos afirmar una relación lineal entre las variables.

## Verificación del supuesto de homogeneidad de covarianzas

La homogeneidad de varianzas puede ser evaluada utilizando la prueba M de Box, implementada en el paquete `rstatix`

```{r}
box_m(iris2[,c('Sepal.Length','Petal.Length')], iris$Species)
```

Con un resultado significativo en el nivel de 0.001, los datos violan el supuesto de homogeneidad en las matrices de covarianza. 

## Verificación de la homogeneidad de varianzas

Para cada una de las variables, el análisis de MANOVa asume que las varianzas entre grupos son iguales. Esto se puede revisar usando el test de Levene para igualdad de varianzas:

Procedimiento:

1. agrupar las variables en parejas de identificador-valor
2. agrupar por variable
3. Ejecutar el test de levene

```{r}
iris2 %>% 
  gather(key = "variable", value = "value", Sepal.Length, Petal.Length) %>%
  group_by(variable) %>%
  levene_test(value ~ Species)
```

Dado que el estad[istico de levene es signficante para cada una de las variables en un nivel de significancia de 0.05, lo que permite rechazar la hipótesis de homogeneidad de varianzas.

Si no se presenta homogeneidad de varianzas, es aconsejable transformar la variable de respuesta.

# Calculo de MANOVA

Existen cuatro estadísticos que pueden utilizarse para el cálculode MANOVA:

* Pillai
* Wilks
* Hotelling-Lawley
* Roy

El más usado y recomendado es el lambda de wilks. 

Aún así, el rastro de pillai es mas robusto y se recomienda cuando se tiene un diseño no balanceado, y el resultado de la prueba de box M es significativo (Como en este caso)

el metodo de pillai es el método que viene por defecto en la funcion `Manova()` del paquete `car`.

para calcular el MANOVA primero creamos el modelo lineal:
```{r}
model <- lm(cbind(Sepal.Length, Petal.Length) ~ Species, iris2)
```
```{r}
Manova(model, test.statistic = "Pillai")
```

Dado que estamos analizando dos variables independientes, es aconsejable utilizar una corrección para pruebas multiples de Bonferroni, lo cual consta de disminuir el nivel de significancia.

esto se puede hacer dividiendo el nivel clásico (0.05) en el número de pruebas, o variables evaluadas. En este caso el resultado del nivel seria 0.025.

El resultado significativo de esta prueba indica que hay diferencias entre los grupos (la especie de la flor) en las variables combinadas.

 

# pruebas post - hoc

Una vez se tiene un resultado estadisticamente significativo para el MANOVA de una via, se puede continuar con el **anova univariado de una via** para examinar de manera separada cada variable. El objetivo es identificar cuales variables son las que contribuyen al efecto global significativo.

## ANOVA univariado de una via

El procedimiento es analogo al anterior:

1. Agrupar los valores de las variables en parejas de identificador - valor. 
2. agrupar por variable:

```{r}
grouped.data <- iris2 %>%
  gather(key = "variable", value = "value", Sepal.Length, Petal.Length) %>%
  group_by(variable)
```


3. realizar el ANOVA de una via

existen tres funciones diferentes en r para calcular el ANOVA de una via dependiendo de cuales supuestos se cumplen:

* `anova_test()` [rstatix]: Se puede usar cuando se cumplen los supuestos de normalidad y homogeneidad.

```{r}
grouped.data %>% anova_test(value ~ Species)
```

* `welch_anova_test()` [rstatix]: Se puede usar cuando el supuesto de homogeneidad no se cumple, como en este caso.

```{r}
grouped.data %>% welch_anova_test(value ~ Species)
```

* `kruskal_test()` [rstatix]: Una alternativa no parametrica para el cálculo de ANOVA

```{r}
grouped.data %>% kruskal_test(value ~ Species)
```

Para las tres pruebas se presenta significancia para ambas variables, longitud del sepalo y longitud del petalo, a lo largo de los grupos de especie.

## comparaciones pareadas

Una vez se obtiene un ANOVA unviariado significativo, es posible hacer comparaciones pareadas para determinar cuales grupos son diferentes.

Si el supuesto de homogeneidad de varianza se cumple, se puede utilizar la función de R `tukey_hsd()`.

Si no se cumple el supuesto de homogeneidad de varianzas, como en este caso, es posible utilizar una prueba post-hoc de Games-Howell. 

Lo anterior también se puede hacer utilizando la función `pairwise_t_test()` del paquete `rstatix` utilizando los argumentos `pool.sd = FALSE` y `var.equal = F`

```{r}
pwc <- iris2 %>%
  gather(key = "variables", value = "value", Sepal.Length, Petal.Length) %>%
  group_by(variables) %>%
  games_howell_test(value ~ Species) %>%
  select(-estimate, -conf.low, -conf.high) # Remove details
pwc
```

Tenemos como resultado que todas las comparaciones pareadas son significantes para cada variable, longitud de petalo y longitud de sepalo.

# Conclusion

Se realizo un analisis de varianza para determinar el efecto del grupo (especie) en la longitud del sépalo y la longitud del pétalo. Existen tres especies diferentes: setosa, versicolor y virginica.

Se presenta una diferencia estadisticamente singnificativa en las variables independientes combinadas (longitud de sepalo y petalo)`F(4, 294) = 71.829, p < 0.0001`

Analisis univariados de ANOVA utilizando un alfa ajustado de bonferroni de 0.025 presenta una diferencia significativa entre la longitud del sepalo `(F(2, 147) = 119, p < 0.0001 )` y longitud del petalo `(F(2, 147) = 1180, p < 0.0001 )` entre las especies.

Todas las comparaciones pareadas mostraron ser significantivas para cada variable (longitud del sepalo y el petalo).

